CellWave -- prototype whole cell modeling framework
---------------------------------------------------

2005-12-21:   Back at it. 
  -- Reaction2Buffer seems to be the right version. 
  -- Let's add:
     * IP3 buffering
     * semi-implicit timestepping on the buffers

General notes:
  --  add documented test/reference cases.
      -- write a parameters-> tex-table converter
      -- standard format for tests & reference cases

InterpolatePoints class:
 -- changes:
    * added 'ignoreGrid'
    * TODO -- add check to buildInterpInfo/ interpolatePoints( q )
    *         .. if I forget to call 'buildInterpInfo' --> print error msg

ideas:
  --  add version tag/build number
  --  demo version of OXCWave to Overture/examples, with matched bcs
  --  add CellWaveParameters -- contain solver info etc.

**
**   ParameterDocumentation          **** IMPORTANT!!
         --> add parameter descriptions for documentation!!
        ParameterDocumentation doc
        doc.header("name")
        doc.newParameter("dt","maximum timestep");

  PARAMETER READER:
  -- look at the ParameterReader hacks in CellWave
     -- arrays
     -- bool
     -- parameter print?
     -- parameter documentation?
  ==> incorporate to one standard ParameterReader
  ==> Put in FastTools

  FLUX BC NOTES
  -- the InterpolatePoints class has hardwired at most 5 components in
     the composite grid functions--> this will need to be changed
  -- currently asserts in the FluxBC class protect against overrunning
     the 5 species limit.

  MULTIBLOCK NOTES:
  --  use multiblock!! with Overture -- look at billsMatchedSquares.cmd
      --> no flux for Calcium, flow through for IP3
  -- look at GridFunction/BoundaryOperators, L 750-->
     ** try getting dc/dn on whole boundary, even if there's a mixed bc 
       ( as in matched squares )
     ** test: get 1 field to go through, and the other to stay in (dc/dn=0)
  ** Flux/jump BC's have Overture BC =2 *** OvertureBC = 2 


  TIMESTEPPER NOTES:
  -- need: dt calculator, rez study generator
  -   TZ solutions?
  --  better timesteppers:
      --  RK
      --  add split step for rxn, CVODE
      --  CVODE: separate integrators/grid -- asynchronous.

2003-09-22:
 -- NEXT: 
    *run dbg_2buffer_fluxbc6.par (with 33 cells)
        & dbg_2buffer_fluxbc7   (with 7 cell geom., running on tux52->OUT)
    *integrate total amount of each species in each cell-->output time history
    *top flux bc for IP3 
 -- progress:  use cellwave/dbg-2buffer_fluxbc5.par
     case 1)
       no flux bc         = 0  # flux bcs on
       name of grid file  = Grids/debug-simple-hirose-7cells.hdf
       --> bug in the corner of cell 20 (cell 7 in simple grid)
     case 2)
       no flux bc         = 1  # flux bcs off
       name of grid file  = Grids/debug-simple-hirose-7cells.hdf
       --> unstable
     case 3)
       no flux bc         =1  # flux bcs off
       name of grid file  = Grids/debug-simple-hirose-just-cell20.hdf
       --> stable

     WHY?  -->> FOUND IT!!!
 -- one more bug. at the end I get: Segmentation fault  --> run valgrind

 -- turned off flux bc--> after all bcs, I set all bc's to Neumann=0
         ==> debug!!  let's see if case 2 blows up still


    Range comps(0, chem.getNumberOfSpecies()-1);
    q.applyBoundaryCondition(comps,BCTypes::extrapolate,BCTypes::allBoundaries,0.);
    q.periodicUpdate();
    q.finishBoundaryConditions(); //..not finished yet, but sets the corners correctly
    // (4b): apply flux BC

    const int numSpecies=chem.getNumberOfSpecies();
    fp.dataCopy(q);

    //..impose flux & noflux bcs
    for ( int ic=0; ic< chem.getNumberOfSpecies(); ++ic ) {
      if ( chem.hasFluxBC( ic ) ) {
	double fluxCoeff= chem.getFluxBCCoefficient( ic );
	setFluxBCCoefficient( fluxCoeff );
	applyFluxBoundaryConditions( q, ic );
      }
      applyNoFluxBoundaryConditions( q, ic);
    }
    //#endif
    //..NEW STATEMENT HERE!! Sets Neumann explicitly.
    //---> I get it: applyNoFluxBC sets only physical. But it should set
    //      also fluxBCs for components without fluxBC's
    q.applyBoundaryCondition(comps,BCTypes::neumann,BCTypes::allBoundaries,0.);
    q.finishBoundaryConditions(); 


2003-09-15:
 --  the diffusion code with flux jump bcs works. Why don't cellwave's flux
     jump bcs work?  Could it be the multicomponent business?
     ** do component by component
 

2003-06-12:
  -- cellwave flux bc -- the jump is ok in FluxBC, but I'm not getting 
     the right Neumann bc on the species... why? (ref_2buffer_slepchenko6.par)
     ** go to a 2d problem, look at the ghostlines--> in ref_2buffer_slepchenko6.par
        --> for some reason, I don't set the correct Neumann bc on both grids.
  -- CONTINUE work on ref_2buffer_slepchenko8.par
     ** 2d testcase with 9 cells from hirose
     ** currently seg.faults, why?
     ** get that to work
  -- Workout empirical limit on dt.

2003-06-11:
  -- cellwave flux bc --> interpolates ok but sets jump==0
  --> FOUND THE CW FLUXBC BUG. I can now set the flux bcs
  -- next bug: the tstepper blows up...
     --> write a one-d solver with jump bcs
     --> figure out finally the dt limit

2003-06-07:
  -- fixing the interp code.

2003-05-30:
  -- getting ready to release:
     ** fluxBC is close, but no cigar. I'll need to hack some more
     ** add flag 'no flux bc'=1 --> removes the flux bc

2003-05-28:
  -- found earlier this week bugs in the IP3 initial data code--> fixed
  -- waves will trigger if not much buffer is present. 
     ... and conversely, too much buffer will prevent Ca2+ triggering. 
     --> Fix this after the FluxBC
  -- hacking on Flux BC optimization:
     .. Working using the new InterpolatePoints _class_ (had to upgrade 
        to Overture 2003-05-28 from CVS)
     .. added ignoreGrid( npoints ) ARRAY to InterpolatePoints
     .. The outline is:
        1) build interp points
           -- go through the current flux bc loop & collect the xyz coords
              for each edge
           -- also, store indexStart/indexEnd pointers to the interp. vector
           -- use SimpleArray<int> to keep the keys, and SimpleArray<bool>
              to keep interp/do not interp flags
           -- the interpolation step is performed in one step for ALL GRIDS
              ==> this results in a single vec with the necessary jumps in it
           -- to apply the JUMP, we unpack the global interp. vector to 
              local vectors on the edge, dimensioned appropriately.
              ==> no need for two composite grid functions to make this work.

        2) in tstepping loop, apply interp stencils

2003-05-21:
  -- the 2Buffer model runs, but is it right?
     -- I have the 3D code (cellwave)
     -- 1D code (radialSolver)
     -- ODE code (ode2Buffer)
    --> these all use the same rxn code & same param files
  -- The Calcium buffers are quite painful. I want RBA.
     ( allow automatic equilibriation of buffers w/ calcium)
  -- test_trig_2buf_7.par --> ODE version fires periodically,
     but cellwave does not!! The solver is broken...
    --> test with 0 diffusion
  ** NEW TEST: run on 5x5 square in 2d with no diffusion -> better get ode results.


2003-04-29:
  -- got the FluxBC class working, albeit it's quite slow
  -- Need to understand the dt limit, clearly I'm getting a bound
     from the boundary.
  -- To do: let's run a fully explicit case with 110,000 grid points
     for 10^7 steps!! How hard can it be...
   -- with Aaron:
     1) waves in a box --> wavespeed et al
     2) waves in a system of epithelialcells
     3) later, ion channels?

2003-04-01:
  -- got first version of epithelial grid to work with testInterpolate3D
     * did a short run -> I do get a little bit of diffusion to neighbors
     * problems:
        - not all cells have proper bcs 
        - worse: some edges are mixed internal/external boundaries
        - corners -- crummy results

2003-03-30:
  -- added 2Buffer
  -- ** work out the interp code >> try testInterp3D with EpiCell grid
      ** make the cell resol. roughly same
      ** make internal bdries no cut but with BC=2 for internal, BC=1 else
      ... and then try diffusion with  Fick bcs !!

  -- added nullClines.m
       ** try nullClines2Buffer(params,0.15) and around
       --> nice, c_max=0.9, c_min =0.05
       --> tweak the IP3 concentration so that p=1 uM gives only 
           the top steady state
           - p=0.1 should give only bottom steady state
           - p=0.3 should give two states
       --> now: p=0.15, bistable, cmax=0.9
                p=0.2 , top state, cmax=1.2
                p=0.12, bottom state, cmax=0.05
        ----> scale d_I & v_c so that J_0 is same for p=(0.1, 0.3, 0.9)

         
2003-03-24:
  -- the interpolant is ok, also in 3D
  -- now separate to a class/sub for use in cellwave
  -- first, try with multiple components, apply bc's on just 1 component
  -- write a solver factory --> replaces the factory code in cellWaveMain
  -- new rxn/solver: 2 Buffer model with IP3 diffusion & CORRECT Li-Rinzel!!!
      ** map the Slepchenko parameters to it!

2003-03-18:
  -- BUG: the oscillating interpolant is a result of getting the 
     value from the wrong grids...
     ** interpolating to Grid=0, the interp. is from grid 1, grid 0,
        grid 1,.... etc. Of course the value jump 1, 0, 1, 0, ...
     ** FIX: restrict interp. only to certain grids!! How
             is it possible it still goes and interpolates
             from the wrong grid?
2003-03-18:
  -- done: 3D interpolation for flux BC test code
     * todo:
     --> isolate the flux bc computer to a set of subs
     --> use with Li-Rinzel. 
     --> use with slepchenko (need to add IP3 dependence).
     --> do 2D & 3D runs
     --> accuracy? stability? writeup.
  

2003-03-17:
  -- connect two matching squares with interpolatePoints
  -- write a wrapper to interpolate --> I want u values from 
     the other grid(s) at given pts. 
  -- wrote 'testInterpolate.C'  for trying interpolation to set flux bc
     using interpolated values from other grids
     Q:  is the piecewise linear interp. enough? Accuracy? Stability?
     Q:  why wiggles on grid 0? but not on grid 1?
     Q:  check & reproduce Sneyd/Wetton original epithelial cell comp

2003-03-13:
  -- working on matched squares, get dc/dn=0 on mixed bcs where p goes through
     -- testMatchedBoundaryFluxBC
        -- something is wrong with the way the second grid is solved
	   ... somehow the solution stays very large on the interp boundary,
               which drives the solution in the bottom grid--> it never goes to zero
           ... zero is the longtime stable state

2003-03-11:
  -- I have a radial solver
     -- get the waves to trigger
     -- look at the outflow condition, looks funny.

2003-03-10:
  -> working on 'radialSolverSlepchenko2Buffer.C' -- testing not done
  **** LOOK AT TIME OFFSET -- make sure t=tcomp + timeOffset >0 always

  --- idea: test radially symmetric solutions, and 
           compare with rxn's from a pt source on the wall
  --- NEED: 
        * add exact gaussian initial data: "GenericCalciumIP3Reaction"
        * do some tests
  --- Compare with results from full code in a box!!
      -- extract radial data with probes.
      -- could even extract pts at a rather dense resolution to match
         1-d code!!
  --- try 2d/3d code, see if the solutions are radially symmetric for source on the wall

  -> look at epithelial cell grids: what's needed to connect in 3D

2003-02-23:
  - heatKernel.h/.C --> use as initial data for IP3
  - try some runs with this, full buffering
  - could I do 3D radially symmetric waves? with the ode code?
    --> special case, add r terms to diffusion
    --> start from r=0, no flux bc?
  - WRITE UP the diffusion_ers.txt
    --> plot some heat kernel's
    --> show the error behavior
    --> try some waves
  - timings? standard cases: 20x20x20, 40x40x40, 80x80x80
  - look at the epi grids. fix the resolutions, connect in 3D


2003-01-26:
  - add probes
  - do diffusion tests
  - do egg tests
  - try non-buffered & buffered versions

  - look at epi grids --> could I connect them up?
  - add to the solver the correct bcs:
     1) dc/dn = 0 at intercell bdries,
     2) p is continuous!

2003-01-17:
  - look at the bc code --> should impose:
    * no flux on calcium at cell walls
    * flux through on IP3 at gap junctions.

2003-01-15:
  - meeting with AQ, showed new nucleus support
  - agreed to debug the box21 geometry
     >> box nucleus, box cell, looking at IP3 diffusion

2003-01-02:
  - Nuclei:  adding support for Nuclei/ a Nucleus
    * grids must contain the nucleus data
    * hence, save grids to a showfile!
  - Nuclei can be generated automatically, in epi2ogen
    * compute some reasonable radius and place one nucleus/cell
    * the nucleus-info is saved to a file
    * the file is input to cwGridGen
    * the .cmd file from epi2ogen could contain a line with '#@cwGridGen nuclei=xxx'
    

2002-12-10:
  - adding CVODE supprt -- see callingCVode.C
   --> work out how to do it, finish the example & writeup
  - release the fully explicit version


2002-11-27:
  - worked on grids
  - first 'release' cw_2002_11_27
  - merge DEC changes back to main source from ~/CellWave/releases/cw ...
  - 

2002-11-08:
  - worked out probes -- see probeSnippet.C
     -- add param file option
     -- use probeSnippet code to output the data
  - next: add initial data options to param file
  - next: work with the timestepper -- split step/cvode

2002-11-06:
  - fixed the param file for ode's 
  - fixed cellwave for Li Rinzel -- it fires again. Jolly good.
  - KEY for demo
    - Slepchenko 2 buf model
    - 3D egg
    - initial data options for reproducing the Slepchenko paper
    - some docs for the parameters
    - simple 3D epi/cellgrid complex 

  - TODO:
     * add release target to make file
     * add Slepchenko 2 buffer model
       -- get it to run on Linux
       -- get it to run on Dec
     * add initial data options: IP3 blob, homog, radial w/ grad
            -- same for Ca
   - Copy LiRinzel rxn -> Slepchenko...
     - Rxn, Solver
   - Keep same progr. model, not most general yet

2002-11-05:
  - fix the rxn code: I'm not getting trav. waves for some reason
    -- should I do the 1-d code? 
  - how do I check this? do some tests:
    * list them
    * make sure I can repeat them
    * collect the data automagically, process into a tex file/writeup


2002-11-04:
  - Was sick since 10/25 :(
  - DONE:
    * parameter file interface to LiRinzelWagner rxns
      -- see 'lirinzel.par' for an example
    * separated generic functionality to solver base class
      --> GenericSolver, GenericReaction
  - TODO:
      -- explicit buffer model, use modest k_off, k_on
      -- debug levels/debug code in systematic way
         ==> leave it in the code, but turn it off
      -- the Ca wave doesn't work right now
      -- epiGridBuilder:
         * given a polygon network, produce 2D or 3D overset gridfile system
      -- initial data from param file:
         ** parse the initial data type

2002-10-25:
  - DONE:
    * multiblock test -- billsMatchedSquares.cmd
  - In progress:
    * started ExplicitSolver : GeneralSolver -- separate solver modules
    * add parameter reader
    * allow more general species, towards adding buffers
    
2002-10-24:
  - DONE:
    * diffusion dt step size
    * main is now cellWaveMain, main exe is 'cellwave'
    * added CellWaveInfo, nothing there yet    
   
2002-10-21:
  - add param. files

2002-10-18:
  - started proto_ <date>_v4 ... try IP3 diffusion!!

  - proto_ <date>_v3 works
  - chemistry RHS is evaluated FORTRAN style
  - otherwise same as alpha_cw
  - oxcwave3D-test1 works on DEC/gps01, see Overture/primer, and CellWave dir.

2002-10-18:
  - alpha_cw works
  - alpha_cw  _v2 has correct initial data eval, and 
    runs sphericalCell_explicit_1mm.cmd ok,
    also 2D oocyte_1000_um.cmd ok
  - make sure grid is about 1mm size, with 10 um rez
  - dt, nsteps etc from command line
  - summary with CPU time at end

2002-10-17: continue alpha_cw_xx ( chem & the main prog)
- plan: first get initial data to work with Fortran loops
- then get RHS eval to work with Fortran loops
- then use Fortran ops for the laplacian??
- NEXT: 
    make alpha_cw
    - add make file targets, get it to compile & run


2002-10-17: TODO
 - build OXCWave on Dec's, setup for a demo on Monday
 - finish alpha_cw (=alpha_cw_2002_10_17), some flavor
 - prep. a 'release' to build for AQ
 - work on rxn code to encapsulate alpha_cw_2002_10_17 ideas 
   --> c++ class etc.

2002-10-17: REMARKS
* initial version will be 0.1.0
* pre 'cellwave' is OXCWave
* code versions/flavors:
   cartCellWave    = embedded bdry Cartesian grids
   overCellWave    = Overture/CellWave
* keep repo separate from distributions
  -- have a 'make release' target
  -- tag the released version
* dev versions are 0.x.y-year-mm-dd-<build number>
  -- generate automatic build numbers
  -- versions should be able to return their release number
* Serial/Parallel versions
   CellWave     single processor code
   CellWave-MP  threaded    (pthreads or OpenMP)
   CellWave-D   distributed (MPI)


